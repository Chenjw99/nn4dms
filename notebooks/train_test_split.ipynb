{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting datasets into train, tune, and test sets\n",
    "This notebook shows how to split datasets into train, tune, and test sets. The splits can be saved to a folder for reuse and reproducibility (recommended).\n",
    "\n",
    "You can generate three types of splits. \n",
    "- A \"super test\" or withholding split. It's a simple random sample of variants meant to be completely held out until the final model training and evaluation.\n",
    "- Classic train-tune-test splits based on percentages of the total dataset. \n",
    "- Reduced train size splits for testing model sensitivity to smaller training set sizes.\n",
    "\n",
    "You can also write your own function to generate a split based on whatever criteria you like. As long as there's a \"train\" set (and a \"tune\" set if you're using early stopping), it should work with the rest of the codebase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload modules before executing code in order to make development and debugging easier\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this jupyter notebook is running inside of the \"notebooks\" directory\n",
    "# for relative paths to work properly, we need to set the current working directory to the root of the project\n",
    "# for imports to work properly, we need to add the code folder to the system path\n",
    "import os\n",
    "from os.path import abspath, join, isdir\n",
    "import sys\n",
    "if not isdir(\"notebooks\"):\n",
    "    # if there's a \"notebooks\" directory in the cwd, we've already set the cwd so no need to do it again\n",
    "    os.chdir(\"..\")\n",
    "module_path = abspath(\"code\")\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import constants\n",
    "import split_dataset as sd\n",
    "import utils\n",
    "\n",
    "# set logging level to info\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "logger = logging.getLogger(\"nn4dms\")\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating a \"super test\" set\n",
    "\n",
    "I recommend using a completely held-out supertest set. Don't use this set for development of the algorithm and don't look at evaluation results on this set until the very end, when you are ready to publish. Here we will create a supertest set for avgfp and save it to the avgfp splits directory in data/avgfp/splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nn4dms.split_dataset:saving supertest split to file data/avgfp/splits/supertest_wf333b1bd195c_s0.1_r12.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([48689, 22582, 38827, ..., 34538, 27872, 39568])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the full dataset (really, we only need the # of variants in the dataset, but this is easier)\n",
    "ds = utils.load_dataset(ds_name=\"avgfp\")\n",
    "\n",
    "# specifying an out_dir will save \n",
    "supertest_idxs = sd.supertest(ds, size=.1, rseed=12, out_dir=\"data/avgfp/splits\", overwrite=True)\n",
    "supertest_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating a classic train-tune-test split\n",
    "You must specify the size of each set as a fraction of the total number of examples. You can specify a fraction of 0 if you do not want to have a particular set. Train + tune + test must sum to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nn4dms.split_dataset:saving train-tune-test split to directory data/avgfp/splits/tr0.6_tu0.2_te0.2_wF_r12\n"
     ]
    }
   ],
   "source": [
    "split = sd.train_tune_test(ds, train_size=.6, tune_size=.2, test_size=.2, rseed=12, out_dir=\"data/avgfp/splits\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tune': array([48689, 22582, 38827, ...,  3939, 32187, 29872]),\n",
       " 'test': array([11269, 32373,  5628, ..., 29229,  3959, 25899]),\n",
       " 'train': array([29742,  8044, 31001, ..., 51795, 49237, 30134])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these sets include the variants from the supertest set we created above. In order to generate a train-tune-test split without those variants, you must specify the either the supertest indices as an array or the filename if you saved them to the disk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nn4dms.split_dataset:saving train-tune-test split to directory data/avgfp/splits/tr0.6_tu0.2_te0.2_wf333b1bd195c_r12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'stest': array([48689, 22582, 38827, ..., 34538, 27872, 39568]),\n",
       " 'tune': array([ 4223, 49475, 33378, ...,  4728, 49730, 51157]),\n",
       " 'test': array([46162, 51625,  1508, ..., 52595, 26108, 24195]),\n",
       " 'train': array([50942, 47964, 52040, ..., 19323, 21347,   656])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supertest_fn = \"data/avgfp/splits/supertest_wf333b1bd195c_s0.1_r12.txt\"\n",
    "split = sd.train_tune_test(ds, train_size=.6, tune_size=.2, test_size=.2, \n",
    "                           withhold=supertest_fn, rseed=12, out_dir=\"data/avgfp/splits\", overwrite=True)\n",
    "split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The supertest set is added to the split as a \"withheld\" set, and the train, tune, and test sets do not contain any variants from it. The save directory contains an alphanumeric string \"f333b1bd195c\" representing a hash of the withheld indices. This is added to handle the edge case where you have multiple supertest sets and want to make multiple splits based on them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating a reduced train size split\n",
    "Similar to generating a classic train-tune-test split, this function takes the size of the tune and test set as a fraction of the total data. The train set size is specified as a proportion of the data remaining after the tune and test sets have been selected. So, if a you specify a 20% tune and a 20% test size, that leaves a pool of 60% for selecting the test set. If your test set proportion is 50%, then the the function will randomly select half the variants from the 60% pool. You must also specify how many train samples of the given size you want. Using multiple samples is important because you may get a really good or really bad training set by chance, especially if you are using a small training size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nn4dms.split_dataset:saving reduced split to directory data/avgfp/splits/reduced_tr0.5_tu0.2_te0.2_wf333b1bd195c_s5_r12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'stest': array([48689, 22582, 38827, ..., 34538, 27872, 39568]),\n",
       "  'tune': array([ 4223, 49475, 33378, ...,  4728, 49730, 51157]),\n",
       "  'test': array([46162, 51625,  1508, ..., 52595, 26108, 24195]),\n",
       "  'train': array([23819, 27807, 10803, ...,  6478, 51121, 17221])},\n",
       " {'stest': array([48689, 22582, 38827, ..., 34538, 27872, 39568]),\n",
       "  'tune': array([ 4223, 49475, 33378, ...,  4728, 49730, 51157]),\n",
       "  'test': array([46162, 51625,  1508, ..., 52595, 26108, 24195]),\n",
       "  'train': array([48548, 44186, 33607, ..., 20771, 52892,  2830])},\n",
       " {'stest': array([48689, 22582, 38827, ..., 34538, 27872, 39568]),\n",
       "  'tune': array([ 4223, 49475, 33378, ...,  4728, 49730, 51157]),\n",
       "  'test': array([46162, 51625,  1508, ..., 52595, 26108, 24195]),\n",
       "  'train': array([ 2098, 51006, 28612, ...,   438, 17146, 53031])},\n",
       " {'stest': array([48689, 22582, 38827, ..., 34538, 27872, 39568]),\n",
       "  'tune': array([ 4223, 49475, 33378, ...,  4728, 49730, 51157]),\n",
       "  'test': array([46162, 51625,  1508, ..., 52595, 26108, 24195]),\n",
       "  'train': array([18875, 51882, 30975, ...,  1059, 33408, 14718])},\n",
       " {'stest': array([48689, 22582, 38827, ..., 34538, 27872, 39568]),\n",
       "  'tune': array([ 4223, 49475, 33378, ...,  4728, 49730, 51157]),\n",
       "  'test': array([46162, 51625,  1508, ..., 52595, 26108, 24195]),\n",
       "  'train': array([50373, 40181, 10151, ..., 42430, 25024, 52827])}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = sd.reduced_train_size(ds, tune_size=.2, test_size=.2, train_prop=.5, num_train_reps=5,\n",
    "                               withhold=supertest_fn, rseed=12, out_dir=\"data/avgfp/splits\", overwrite=True)\n",
    "splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since multiple train replicates were specified, the result is a list of splits. Note that the tune and test sets are exactly the same as the previous section. This is because we used the same random seed as above and is the desired behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading a saved split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': array([50942, 47964, 52040, ..., 19323, 21347,   656]),\n",
       " 'stest': array([48689, 22582, 38827, ..., 34538, 27872, 39568]),\n",
       " 'test': array([46162, 51625,  1508, ..., 52595, 26108, 24195]),\n",
       " 'tune': array([ 4223, 49475, 33378, ...,  4728, 49730, 51157])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dir = \"data/avgfp/splits/tr0.6_tu0.2_te0.2_wf333b1bd195c_r12\"\n",
    "split = sd.load_split_dir(split_dir)\n",
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'train': array([18875, 51882, 30975, ...,  1059, 33408, 14718]),\n",
       "  'stest': array([48689, 22582, 38827, ..., 34538, 27872, 39568]),\n",
       "  'test': array([46162, 51625,  1508, ..., 52595, 26108, 24195]),\n",
       "  'tune': array([ 4223, 49475, 33378, ...,  4728, 49730, 51157])},\n",
       " {'train': array([50373, 40181, 10151, ..., 42430, 25024, 52827]),\n",
       "  'stest': array([48689, 22582, 38827, ..., 34538, 27872, 39568]),\n",
       "  'test': array([46162, 51625,  1508, ..., 52595, 26108, 24195]),\n",
       "  'tune': array([ 4223, 49475, 33378, ...,  4728, 49730, 51157])},\n",
       " {'train': array([ 2098, 51006, 28612, ...,   438, 17146, 53031]),\n",
       "  'stest': array([48689, 22582, 38827, ..., 34538, 27872, 39568]),\n",
       "  'test': array([46162, 51625,  1508, ..., 52595, 26108, 24195]),\n",
       "  'tune': array([ 4223, 49475, 33378, ...,  4728, 49730, 51157])},\n",
       " {'train': array([23819, 27807, 10803, ...,  6478, 51121, 17221]),\n",
       "  'stest': array([48689, 22582, 38827, ..., 34538, 27872, 39568]),\n",
       "  'test': array([46162, 51625,  1508, ..., 52595, 26108, 24195]),\n",
       "  'tune': array([ 4223, 49475, 33378, ...,  4728, 49730, 51157])},\n",
       " {'train': array([48548, 44186, 33607, ..., 20771, 52892,  2830]),\n",
       "  'stest': array([48689, 22582, 38827, ..., 34538, 27872, 39568]),\n",
       "  'test': array([46162, 51625,  1508, ..., 52595, 26108, 24195]),\n",
       "  'tune': array([ 4223, 49475, 33378, ...,  4728, 49730, 51157])}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_split_dir = \"data/avgfp/splits/reduced_tr0.5_tu0.2_te0.2_wf333b1bd195c_s5_r12\"\n",
    "splits = sd.load_split_dir(reduced_split_dir)\n",
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
